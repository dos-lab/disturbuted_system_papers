# Title

<!-- 此部分是论文标题及其引用格式，建议使用latex格式 -->
Best VM Selection for Big Data Applications across Multiple Frameworks by Transfer Learning

## Website

https://doi.org/10.1145/3472456.3472488

## Citing

Yuewen Wu, Heng Wu, Yuanjia Xu, Yi Hu, Wenbo Zhang, Hua Zhong, and Tao Huang. 2021. Best VM Selection for Big Data Applications across Multiple Frameworks by Transfer Learning. In 50th International Conference on Parallel Processing (ICPP '21), August 9–12, 2021, Lemont, IL, USA. ACM, New York, NY, USA, 11 pages.

## Brief Introduction

<!-- 通过三五句话描述这篇文章，包括 1. 论文的应用场景；2. 论文克服已有方法的局限性；3. 论文主要的技术手段； 4. 论文的预期结果 -->
当前用户由于业务需求通常选择多个大数据框架进行数据分析，且主流的大数据框架有数十种之多，云配置择优面临框架异构性的挑战。已有机器学习相关工作（PARIS@SoCC 2017）大多复用已学习应用构建的模型（应用来源于一个或几个大数据框架）进行云配置择优，然而此方法并不适用于大数据应用跨框架的场景，将已学习应用构建的模型直接复用于未学习大数据框架之上将导致严重的预测误差，而重新构建模型可能需要数百小时的数据收集、模型训练开销。另一方面，对于执行相同或相似任务的大数据应用，即使存在框架上的差异，应用之间也可能体现出相同或相似的资源关系（Figure 1），进而具有云配置择优知识互通与共享的可行性。为此，本论文通过大规模离线分析，深度挖掘跨框架大数据应用的云配置择优知识并构建知识共享模型，采用迁移学习方法实现知识在不同框架的迁移，兼顾模型预测的准确性和模型构建的开销。

## Key Methodology

<!-- 分点写，论述论文中主要技术手段的实施过程 -->
该论文的核心贡献在于发现、表示、复用跨框架大数据应用的云配置择优知识，解决了已有工作难以兼顾模型预测准确性和模型构建开销的问题。


- 基于大规模评估的知识抽象获取

  - 针对 EC2 进行评估

  - 针对不同的用途，设置了不同的基准测试，旨在应对多种应用，以学习框架间的高层相似性。

  - 在每次评估中，收集共 20 个底层特征，以刻画应用的资源需求、执行特征等。

  - 对于高层相似性指标，使用主成分分析其与目标函数的相关性，并使用 K-Means 聚类，以寻找（近）最优虚拟机配置种类。
- 基于两层二分图的抽象知识表示

  - 双层结构：包含源负载与目标负载的负载层-包含高层相似特征的标签层（L）-包含不同虚拟机类型的虚拟机类型层（T）

  - 每种负载包含一个或若干个特征标签，而每种特征标签对应着合适的一种或若干种虚拟机类型。因此，对于含有相同标签的负载，则大概率对应着相同的一种或几种虚拟机类型，至少对虚拟机其中的某些配置的要求相同。

  - 因此，知识的抽象与表示方法为某个负载是否包含某个标签，以及某个标签是否适合于某种虚拟机配置，以此建立矩阵。
- 基于迁移学习的知识复用
  - 目标是最小化目标负载-标签矩阵与现有负载-标签矩阵的差异（用 F 范数表示）
  - 对目标负载，使用沙箱进行试运行，收集底层特征，在此基础上使用 K-Means 聚类，得到虚拟机种类与标签间的关系，分别建立负载-标签、标签-虚拟机种类矩阵。
  - 使用随机梯度下降对矩阵进行收敛。基于收敛后的目标负载-标签矩阵，重新训练 K-Means 模型以建立标签-虚拟机类型的关系，并对当前目标负载，确定最佳虚拟机配置。


## Data Sets & Experimental Design

<!-- 撰写实验环境的设置，实验的对象，实验的比较方面，以及实验的结果（不要列举数据，要概括谈） -->
测试平台：Amazon AWS 120个不同的云主机类型；测试应用：三个大数据框架（Spark、Hadoop、Hive）的30个应用；实验对象：PARIS@SoCC 2017、Ernest@NSDI 2016；评价指标：大数据应用在推荐云配置运行时的性能提升，以及获取推荐云配置产生的训练开销。实验结果表明Vesta相比于实验对象，Vesta能够提升51%的应用性能，并且减少85%的训练开销。


- 实验数据

  Hadoop、Hive 和 Spark 共 30 组负载，分成源负载与目标负载两组

- 实验环境

  120 enterprise-level VM types of x86 architecture from Amazon EC2

- 实验对象
  Vesta, PARIS, Ernest

- 比较方面

  模型预测误差 MAPE、训练成本、运行时间与成本

- 实验结果

  与 PARIS 相比，最高可降低 51% 的模型预测误差。但对 Spark-CF 预测效果不佳，原因是知识库中找不到和其匹配的模型，因此实际预测时需要对模型种类加以限制。

  对于计算密集型负载，Vesta 的执行时间与其他模型更少或相当。

  Vesta 需要较低的训练成本就可以达到最低的 MAPE。

  对于大部分负载，Vesta 需要更少的运行次数就可以达到更优的优化效果，且运行成本更低。


## Conclusion and Future Work

<!-- 作者或者阅读者对本文工作的总结，以及未来可能的改进方向 -->
该论文基于迁移学习解决跨框架大数据应用的云配置择优问题，其大规模离线测试的方法值得借鉴，可用于分析其他主流应用的资源使用特征，例如PyTorch、TensorFlow等深度学习应用。
