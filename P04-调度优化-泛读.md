# job调度

| 论文名称 | 会议期刊 | 调度级别 |目标和环境 | 优缺点 |
| ------ | ------ | ------ | ------ |------ |
| Themis | NSDI 2020 | 实例 | 多租户完成时间公平性 |支持不同模型分布式放置的敏感性 |
| Allox，Gandiva_fair | EuroSys 2020 | 实例 | 保障公平性的同时提升集群效率 |支持新旧CPU\GPU之间的公平交易机制 |
| Ursa | EuroSys 2020 | 算子集合 | 提升集群效率，缩短作业完成时间 |支持DAG数据流 |
| Tiresias | NSDI 2020 | 实例 | 降低作业等待时间，避免通信干扰 |支持数据流优先级和亲和性 |
| kubeShare | HPDC 2020 | 实例 | 提升资源效率 |提供GPU细粒度共享的运行时 |
| SoptLight | IcML 2018 | 算子 | 降低算子集合的运行时间 |基于强化学习预测算子位置 |
| CC-OS | IPDPS 2019 | 算子 | 降低算子集合的运行时间 |基于算子所需CPU线程并发度的动态调整 |
| Olympia，Salus | Middleware 2016，MLSys 2020 | 算子 | 提升GPU资源利用率 |基于算子进行资源分配和共享 |



@article{shin2021elastic,
  title={Elastic Resource Sharing for Distributed Deep Learning},
  author={Shin, Jinwoo and Park, KyoungSoo},
  year={2021}
}

//本方法面相多种不同ML模型预测DL等应用的最优资源使用问题，构造6类典型ML预测模型，面相big Data、DL等典型应用，分析了当前DL方法的预期效果，定义了O-err，BoM-err两个预测准确度衡量指标，通过最优模型测试和模型松弛测试，发现单个ML模型难以有效准确预测多种应用的配置，并给出了导致准确度低的原因。本文说明了ML并不是通用且易调整的解决DL等应用资源需求预测方法，此类黑盒方法具有较大的局限性。也说明基于白盒分析的资源推荐、调度等方法的合理性。
@inproceedings{fu2021use,
  title={On the Use of ML for Blackbox System Performance Prediction.},
  author={Fu, Silvery and Gupta, Saurabh and Mittal, Radhika and Ratnasamy, Sylvia},
  booktitle={NSDI},
  pages={763--784},
  year={2021}
}

//模型：基于DAG依赖的任务调度逐渐成为集群调度的主要对象，当前工作缺乏对调度时间复杂度的近似分析，本文形式化定义了DAG任务使用多种资源时的资源需求和分配需要，定义两个阶段的调度，基于队列结构的近似求解算法定义了此类方法和调度场景下的下界。但其限定条件较为受限，只能支持多种资源间没有关联关系的情况，且需要任务在没中资源上的使用时间已知。
@article{perotin2021multi,
  title={Multi-Resource List Scheduling of Moldable Parallel Jobs under Precedence Constraints},
  author={Perotin, Lucas and Sun, Hongyang and Raghavan, Padma},
  journal={arXiv preprint arXiv:2106.07059},
  year={2021}
}

//机制：单个算子基本包含通信、计算两个基本操作，一般来讲通信会影响到计算（计算等待等原因），本文分析了计算也回反向影响通信，其核心原因是由于内存总线上的竞争导致的，并设计单独通信、单独计算和通信计算并行执行三种HPC的应用场景，来分析内存竞争的延迟情况。能够辅助分析这种竞争产生的原因并分析竞争，其最终可以以计算机硬件拓扑图的形式定位资源竞争。此方法可以基于StarPU设计资源分配的竞争避免组件，但仍然需要在异构资源上持续扩展。
@inproceedings{denis2021interferences,
  title={Interferences between Communications and Computations in Distributed HPC Systems},
  author={Denis, Alexandre and Jeannot, Emmanuel and Swartvagher, Philippe},
  booktitle={50th International Conference on Parallel Processing (ICPP'21)},
  year={2021}
}

//策略：DL模型分布式训练时，数据并行模式需要同步，传统基于梯度优先级的静态设置方法不能充分利用GPU资源，也会使状态同步的等待时间过长。对此，Prophet在BytePS的基础上，使用预测的方法来精准控制通信的时间，通过周期监测网络带宽来提升资源使用效率，相交于优先级方法能最多提升40%的训练效果。
@article{zhang2021prophet,
  title={Prophet: Speeding up Distributed DNN Training with Predictable Communication Scheduling},
  author={Zhang, Zhenwei and Qi, Qiang and Shang, Ruitao and Chen, Li and Xu, Fei},
  year={2021}
}

//机制：基于回归的HPC应用性能评估模型，当受到较多干扰的时候其评估效果较差，Noise使用深度神经网络过滤影响性能模型的因素，提升性能模型预测的准确度
@inproceedings{ritter2021noise,
  title={Noise-Resilient Empirical Performance Modeling with Deep Neural Networks},
  author={Ritter, Marcus and Gei{\ss}, Alexander and Wehrstein, Johannes and Calotoiu, Alexandru and Reimann, Thorsten and Hoefler, Torsten and Wolf, Felix},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={23--34},
  year={2021},
  organization={IEEE}
}


//机制：LFM认为python中的function会成为未来主流的集群调度基本单元，使用function作为基本单元时，会面临function运行环境准备、依赖关系确定、分布式工作节点上的资源管理等问题，其使用Parsl解决依赖关系问题，使用psutil解决资源管理问题，使用多种环境准备方式应对function的快速加载。LFM主要应用于生物、物理等科学计算领域，其时延要求不高，资源效率等问题要求不严格，应用于DL 算子等领域时还需要较多的改进。
@INPROCEEDINGS{9460530,
  author={Shaffer, Tim and Li, Zhuozhao and Tovar, Ben and Babuji, Yadu and Dasso, TJ and Surma, Zoe and Chard, Kyle and Foster, Ian and Thain, Douglas},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)}, 
  title={Lightweight Function Monitors for Fine-Grained Management in Large Scale Python Applications}, 
  year={2021},
  volume={},
  number={},
  pages={786-796},
  doi={10.1109/IPDPS49936.2021.00088}
}


//策略：在异构资源环境下，MS-DF的P2P参数同步方式容易受到慢设备的影响而影响其训练时间，Prague使用局部P2P同步策略提升同一分组下MS-DF的同步速度，同时使用静态分组调度避免随机同步的参数冲突，从而在异构资源环境下保障资源时空复用的性能
@inproceedings{luo2020prague,
  title={Prague: High-Performance Heterogeneity-Aware Asynchronous Decentralized Training},
  author={Luo, Qinyi and He, Jiaao and Zhuo, Youwei and Qian, Xuehai},
  booktitle={Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems},
  pages={401--416},
  year={2020}
}

//模型：E-LAS将训练集数据全部送入MS-DF进行处理的次数（epoch），以及已经获得服务的时间（LAS）之和来作为MS-DF的优先级，由于一个执行过多次epoch的MS-DF更容易收敛且得到更高的优先级，E-LAS能相交于原始LAS进一步缩短完成时间。
@inproceedings{sultana2020design,
  title={E-LAS: Design and Analysis of Completion-Time Agnostic Scheduling for Distributed Deep Learning Cluster},
  author={Sultana, Abeda and Chen, Li and Xu, Fei and Yuan, Xu},
  booktitle={49th International Conference on Parallel Processing-ICPP},
  pages={1--11},
  year={2020}
}

@inproceedings{le2020allox,
  title={AlloX: compute allocation in hybrid clusters},
  author={Le, Tan N and Sun, Xiao and Chowdhury, Mosharaf and Liu, Zhenhua},
  booktitle={Proceedings of the Fifteenth European Conference on Computer Systems},
  pages={1--16},
  year={2020}
}

@inproceedings{chaudhary2020balancing,
  title={Balancing efficiency and fairness in heterogeneous GPU clusters for deep learning},
  author={Chaudhary, Shubham and Ramjee, Ramachandran and Sivathanu, Muthian and Kwatra, Nipun and Viswanatha, Srinidhi},
  booktitle={Proceedings of the Fifteenth European Conference on Computer Systems},
  pages={1--16},
  year={2020}
}

针对DL任务的调度问题，已有工作存在较多问题，kubernetes、yarn的静态调度器过于简单，无法满足实际需要；Optimus等基于DL的建模，其准确度不高（收敛曲线不够平滑）；基于约束和数据本地性考虑，以最少机器和最少网络通信的方法也未必能够提升性能。Tiresias为了有效的调度GPU，最小化JCT，同时提升efficiency，通过对身产环境的job信息进行分析，面向不同的DL模型，提出两种基本思想：基于离散的2D-LAS和2DGittins-index方法。
@inproceedings{gu2019tiresias,
  title={Tiresias: A $\{$GPU$\}$ cluster manager for distributed deep learning},
  author={Gu, Juncheng and Chowdhury, Mosharaf and Shin, Kang G and Zhu, Yibo and Jeon, Myeongjae and Qian, Junjie and Liu, Hongqiang and Guo, Chuanxiong},
  booktitle={16th $\{$USENIX$\}$ Symposium on Networked Systems Design and Implementation ($\{$NSDI$\}$ 19)},
  pages={485--500},
  year={2019}
}

//模型：多个MS-DF共享集群资源环境时只考虑GPU的容量需求是不够的，还需要考虑MS-DF和GPU之间的亲和性，如有些MS-DF使用PCIe连接的GPU资源就能获得相较于使用以太网连接的GPU时更短的完成时间，HiveD即对集群内资源进行不同层次的连接和分组，满足不同资源连接层次情况下的亲和性需要。
@inproceedings{zhao2020hived,
  title={HiveD: Sharing a $\{$GPU$\}$ Cluster for Deep Learning with Guarantees},
  author={Zhao, Hanyu and Han, Zhenhua and Yang, Zhi and Zhang, Quanlu and Yang, Fan and Zhou, Lidong and Yang, Mao and Lau, Francis CM and Wang, Yuqi and Xiong, Yifan and others},
  booktitle={14th $\{$USENIX$\}$ Symposium on Operating Systems Design and Implementation ($\{$OSDI$\}$ 20)},
  pages={515--532},
  year={2020}
}

//讨论深度学习中反馈机制的泛化性问题,多智能体情况：感知、知识、控制、记忆、语言（规划）等。
@article{silver2021reward,
  title={Reward Is Enough},
  author={Silver, David and Singh, Satinder and Precup, Doina and Sutton, Richard S},
  journal={Artificial Intelligence},
  pages={103535},
  year={2021},
  publisher={Elsevier}
}

//策略：确定资源需求后，PTD-P能综合使用张量并行（算子切分）、数据并行和模型并行方法，在避免相互干扰的同时，给出在GPU环境下三层并行方法的实施方式，如确定张量并行的数量、数据并行和模型并行的batchsize取值等，能提升资源使用效率和吞吐量。
@inproceedings{narayanan2021efficient,
  title={Efficient large-scale language model training on GPU clusters using megatron-LM},
  author={Narayanan, Deepak and Shoeybi, Mohammad and Casper, Jared and LeGresley, Patrick and Patwary, Mostofa and Korthikanti, Vijay and Vainbrand, Dmitri and Kashinkunti, Prethvi and Bernauer, Julie and Catanzaro, Bryan and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2021}
}

//机制：面向多个DL共享一个GPU资源的场景，针对DL到来时间不确定、算子资源竞争形式多样以及输入数据量差异较大等问题，提出了以跨模型算子组为基础的算子资源预测方法，能够在预测的基础上合理安排多个算子的执行顺序，以准确预测算子执行延迟。
@inproceedings{cui2021enable,
  title={Enable simultaneous DNN services based on deterministic operator overlap and precise latency prediction},
  author={Cui, Weihao and Zhao, Han and Chen, Quan and Zheng, Ningxin and Leng, Jingwen and Zhao, Jieru and Song, Zhuo and Ma, Tao and Yang, Yong and Li, Chao and others},
  booktitle={Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
  pages={1--15},
  year={2021}
}

//策略：Eflops针对分布式机器学习训练时通信开销较大，参数同步时的带宽拥堵问题，首先使用NIC网卡和一个GPU绑定的方式，避免单机内部通信竞争；然后针对跨主机环境，构造CLOS网络拓扑，使用Bigraph的网络构造，尽可能降低跨主机通信竞争；同时，为了配合网络拓扑，设计新的all-reduce参数同步方式。这种方法能够尽量复用已有的标准以太网和pcie协议，但需要对网络设施进行大量改造。
@inproceedings{dong2020eflops,
  title={Eflops: Algorithm and system co-design for a high performance distributed training platform},
  author={Dong, Jianbo and Cao, Zheng and Zhang, Tao and Ye, Jianxi and Wang, Shaochuang and Feng, Fei and Zhao, Li and Liu, Xiaoyong and Song, Liuyihan and Peng, Liwei and others},
  booktitle={2020 IEEE International Symposium on High Performance Computer Architecture (HPCA)},
  pages={610--622},
  year={2020},
  organization={IEEE}
}

//策略：DAPPLE与PTD-P类似，基于离线分析，确定DNN训练时模型并行和数据并行混合执行逻辑，在模型并行时，进一步结合资源使用情况，适当选择流水线并行方案，提升资源使用效率；同时，结合网络拥堵状态调整参数同步算法，其结果在训练加速和内存资源使用效率方面有提升。
@inproceedings{fan2021dapple,
  title={DAPPLE: A pipelined data parallel approach for training large models},
  author={Fan, Shiqing and Rong, Yi and Meng, Chen and Cao, Zongyan and Wang, Siyu and Zheng, Zhen and Wu, Chuan and Long, Guoping and Yang, Jun and Xia, Lixue and others},
  booktitle={Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
  pages={431--445},
  year={2021}
}

//策略：本文分析了同步、异步两类共7种算子状态同步方法在集群环境下的实际表现，通过模型精度、超参数敏感性、可伸缩性以及状态同步时的优化手段这四类来比较状态同步方法的预期效果，提出了同步方法伸缩性差、瓶颈资源在参数服务器的问题；提出了异步方法node间等待时间长的问题；提出了非等待反向传播方法在GPU上实际效果一般的问题。
@inproceedings{ko2021depth,
  title={An In-Depth Analysis of Distributed Training of Deep Neural Networks},
  author={Ko, Yunyong and Choi, Kibong and Seo, Jiwon and Kim, Sang-Wook},
  booktitle={2021 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={994--1003},
  year={2021},
  organization={IEEE}
}

# operator调度

//针对DNN模型结构、参数量不断增大，需要多级多卡进行DL训练的场景，harmonomy使用算子（组）作为基本的控制单元，以进一步提升资源使用效率。重点通过cpu/gpu间的p2p数据传输解决GPU显存受限的问题，对关键算子进行进一步切分充分使用多种资源。
@inproceedings{li2021doing,
  title={Doing more with less: training large DNN models on commodity servers for the masses},
  author={Li, Youjie and Phanishayee, Amar and Murray, Derek and Kim, Nam Sung},
  booktitle={Proceedings of the Workshop on Hot Topics in Operating Systems},
  pages={119--127},
  year={2021}
}

//HERTI针对有deadline约束的、运行在异构嵌入式设备上的DL实施推理服务，使用DL方法降低算子划分的搜索空间，同时精确估算不同设备间的通信和计算延迟，相较于已有工作能满足异构、QoS的需要。此种方法仍然聚焦于整个layer的资源使用情况，其控制粒度、资源使用效率在引入算子多种切分方法后还能进一步提升。
@inproceedings{han2021herti,
  title={HERTI: A Reinforcement Learning-Augmented System for Efficient Real-Time Inference on Heterogeneous Embedded Systems},
  author={Han, Myeonggyun and Baek, Woongki},
  booktitle={2021 30th International Conference on Parallel Architectures and Compilation Techniques (PACT)},
  pages={90--102},
  year={2021},
  organization={IEEE}
}

//该方法针对单个DNN模型在云边端环境下反复多次运行的场景，使用联合层切分方法降低资源的空闲时间，同时分别调度不同的层。这些方法不涉及到编译优化，也不能控制到单个算子，仅适用于端云边环境下不同的网络连接情况（交叠通信和计算）。
@inproceedings{duan2021joint,
  title={Joint Optimization of DNN Partition and Scheduling for Mobile Cloud Computing},
  author={Duan, Yubin and Wu, Jie},
  booktitle={50th International Conference on Parallel Processing},
  pages={1--10},
  year={2021}
}

//Pesto使用线性规划方法，确定大DL模型在模型并行情况下的同构GPU资源时的最优切分，其核心是设计规划约束避免通信拥堵。其在异构资源上多种混合并行模式的选择仍然需要进一步优化，可持续提升资源利用效率。
@inproceedings{hafeez2021towards,
  title={Towards optimal placement and scheduling of DNN operations with Pesto},
  author={Hafeez, Ubaid Ullah and Sun, Xiao and Gandhi, Anshul and Liu, Zhenhua},
  booktitle={Proceedings of the 22nd International Middleware Conference},
  pages={39--51},
  year={2021}
}

//此方法将DL模型切分不同的阶段，在各个阶段内通过动态优化方法调整其运行时间，以最大化吞吐量；然后在每个阶段内部，通过feature map算子的切分、对工作负载的分析等方式适应多种异构设备。此种方法只适用于CNN环境下多个负载的受限算子，且假设负载是泊松分布，存在一定的局限性。
@inproceedings{yang2021towards,
  title={Towards Efficient Inference: Adaptively Cooperate in Heterogeneous IoT Edge Cluster},
  author={Yang, Xiang and Qi, Qi and Wang, Jingyu and Guo, Song and Liao, Jianxin},
  booktitle={2021 IEEE 41st International Conference on Distributed Computing Systems (ICDCS)},
  pages={12--23},
  year={2021},
  organization={IEEE}
}